# Лекция 0 Поиск

### Искусственный интеллект

**Искусственный интеллект (ИИ)** — это набор методов, которые позволяют компьютеру демонстрировать поведение, схожее с разумным. Например, ИИ используется для распознавания лиц на фотографиях в социальных сетях, для победы над чемпионом мира в шахматах и для обработки вашей речи, когда вы разговариваете с Siri или Alexa на своем телефоне.

В этом курсе мы рассмотрим некоторые идеи, которые делают ИИ возможным:

*   **Поиск:** Нахождение решения проблемы, например, когда навигационное приложение ищет лучший маршрут от начала до конца, или когда игровая программа определяет следующий ход.
*   **Знания:** Представление информации и получение из нее выводов.
*   **Неопределенность:** Работа с вероятностными событиями с использованием теории вероятностей.
*   **Оптимизация:** Нахождение не просто правильного, а лучшего или оптимального способа решения проблемы.
*   **Обучение:** Улучшение производительности на основе доступа к данным и опыту. Например, ваша почта способна отличать спам от не-спама, основываясь на прошлых данных.
*   **Нейронные сети:** Программная структура, вдохновленная человеческим мозгом, способная эффективно выполнять задачи.
*   **Язык:** Обработка естественного языка, который производят и понимают люди.

---

### Поиск

**Проблемы поиска** включают **агента**, которому заданы **начальное состояние** и **целевое состояние** и который возвращает **решение** — как перейти из первого во второе. Навигационное приложение использует типичный процесс поиска: агент (мыслящая часть программы) получает на вход ваше текущее местоположение и пункт назначения и, на основе **алгоритма поиска**, возвращает предложенный путь. Однако, существуют и многие другие формы задач поиска, такие как головоломки или лабиринты.

![image](./.assets/image-1760472800113.png)

Нахождение решения для **пятнашки (15 puzzle)** потребовало бы использования алгоритма поиска.

*   **Агент:** Сущность, которая воспринимает свое **окружение** и действует на него. Например, в навигационном приложении агентом было бы представление автомобиля, которому нужно решить, какие **действия** предпринять, чтобы достичь цели.

*   **Состояние:** Конфигурация агента в его среде. Например, в пятнашке состоянием является любое расположение чисел на поле.

*   **Начальное состояние:** Состояние, с которого алгоритм поиска начинает работу. В навигаторе это текущее местоположение.

*   **Действия:** Выбор, который можно сделать в состоянии. Точнее, действия можно определить как функцию. При получении состояния `s` на вход, `Actions(s)` возвращает набор действий, которые можно выполнить в состоянии `s`. Например, в пятнашке действия для данного состояния — это способы сдвинуть плитки в текущей конфигурации (4 действия, если пустая ячейка в центре, 3 — если рядом с краем, 2 — если в углу).

*   **Модель перехода:** Описание того, какое состояние получается в результате выполнения любого возможного действия в любом состоянии. Точнее, модель перехода можно определить как функцию. При получении состояния `s` и действия `a` на вход, `Results(s, a)` возвращает состояние, полученное выполнением действия `a` в состоянии `s`. Например, для данной конфигурации пятнашки (состояние `s`) сдвиг плитки в любом направлении (действие `a`) приведет к новой конфигурации (новое состояние).

*   **Пространство состояний:** Набор всех состояний, достижимых из начального состояния любой последовательностью действий. Например, в пятнашке пространство состояний состоит из всех 16!/2 конфигураций на поле, которые можно достичь из любого начального состояния. Пространство состояний можно визуализировать как ориентированный граф, где состояния представлены узлами, а действия — стрелками между узлами.

![image](./.assets/image-1760472817882.png)

*   **Проверка цели:** Условие, которое определяет, является ли данное состояние целевым. Например, в навигаторе проверка цели — это находится ли текущее местоположение агента (представление машины) в пункте назначения. Если да — проблема решена. Если нет — продолжаем поиск.

*   **Стоимость пути:** Числовая стоимость, связанная с данным путем. Например, навигатор не просто ведет вас к цели; он делает это, минимизируя стоимость пути, находя самый быстрый способ добраться до целевого состояния.

### Решение задач поиска

*   **Решение:** Последовательность действий, которая ведет от начального состояния к целевому состоянию.

*   **Оптимальное решение:** Решение, имеющее самую низкую стоимость пути среди всех решений.

В процессе поиска данные часто хранятся в **узле** — структуре данных, которая содержит следующее:
*   **Состояние**
*   **Родительский узел**, через который был сгенерирован текущий узел
*   **Действие**, которое было применено к состоянию родителя, чтобы получить текущий узел
*   **Стоимость пути** от начального состояния до этого узла

**Узлы** содержат информацию, которая делает их очень полезными для целей алгоритмов поиска. Они содержат **состояние**, которое можно проверить с помощью **проверки цели**, чтобы увидеть, является ли оно конечным. Если да, то **стоимость пути** узла можно сравнить со стоимостью других узлов, что позволяет выбрать **оптимальное решение**. Как только узел выбран, благодаря хранению **родительского узла** и **действия**, которое привело от **родителя** к текущему узлу, можно проследить весь путь от **начального состояния** до этого узла, и эта последовательность действий является **решением**.

Однако **узлы** — это просто структура данных; они не ищут, они хранят информацию. Чтобы непосредственно осуществлять поиск, мы используем **границу (frontier)** — механизм, который "управляет" **узлами**. **Граница** начинает работу с содержания начального состояния и пустого множества исследованных узлов, а затем повторяет следующие действия до достижения решения:

**Повторять:**
1.  Если граница пуста:
    *   **Стоп.** Решения проблемы не существует.
2.  Удалить узел из границы. Это узел, который будет рассматриваться.
3.  Если узел содержит целевое состояние:
    *   **Вернуть решение. Стоп.**
4.  Иначе:
    *   **Развернуть узел** (найти все новые узлы, которые можно достичь из этого узла) и добавить полученные узлы в границу.
    *   Добавить текущий узел в **множество исследованных узлов**.

---

### Поиск в глубину

В предыдущем описании **границы** одна деталь не была упомянута. На этазе 2 в псевдокоде выше, какой узел следует удалить? Этот выбор влияет на качество решения и скорость его достижения. Есть несколько способов подойти к вопросу о том, какие узлы следует рассматривать первыми, два из которых могут быть представлены структурами данных **стек** (в **поиске в глубину**) и **очередь** (в **поиске в ширину**).

Мы начнем с подхода **поиска в глубину (Depth-First Search, DFS)**.

Алгоритм **поиска в глубину** полностью исчерпывает одно направление, прежде чем попробовать другое. В таких случаях граница управляется как структура данных **стек**. Ключевая фраза, которую нужно запомнить: «последним пришел — первым ушел». После того как узлы добавляются в границу, первый узел для удаления и рассмотрения — это последний добавленный. Это приводит к тому, что алгоритм поиска идет как можно глубже в первом попавшемся направлении, оставляя все другие направления на потом.

**(Пример из жизни:** Представьте, что вы ищете ключи. При подходе **поиска в глубину**, если вы решите начать с поиска в брюках, вы сначала проверите каждый карман, выворачивая их и тщательно просматривая содержимое. Вы перестанете искать в брюках и начнете искать в другом месте, только полностью исчерпав поиск в каждом кармане.)

**Плюсы:**
*   В лучшем случае этот алгоритм самый быстрый. Если ему "повезет" и он всегда будет выбирать правильный путь к решению (случайно), то **поиск в глубину** занимает наименьшее возможное время для достижения решения.

**Минусы:**
*   Возможно, найденное решение не будет оптимальным.
*   В худшем случае этот алгоритм исследует все возможные пути, прежде чем найти решение, thus занимая максимально возможное время до достижения решения.

**Пример кода (удаление узла из стека):**
```python
def remove(self):
    if self.empty():
        raise Exception("empty frontier")
    else:
        node = self.frontier[-1]  # Сохраняем последний элемент в списке
        self.frontier = self.frontier[:-1]  # Удаляем последний узел
        return node
```

---

### Поиск в ширину

Противоположностью **поиску в глубину** является **поиск в ширину (Breadth-First Search, BFS)**.

Алгоритм **поиска в ширину** будет следовать нескольким направлениям одновременно, делая один шаг в каждом возможном направлении, прежде чем сделать второй шаг в каком-либо направлении. В этом случае граница управляется как структура данных **очередь**. Ключевая фраза: «первым пришел — первым ушел». Все новые узлы становятся в очередь, и узлы рассматриваются на основе того, какой был добавлен первым (в порядке живой очереди!). Это приводит к тому, что алгоритм поиска делает один шаг во всех возможных направлениях, прежде чем сделать второй шаг в любом из них.

**(Пример из жизни:** Допустим, вы ищете ключи. В этом случае, если вы начнете с брюк, вы посмотрите в правый карман. После этого, вместо того чтобы смотреть в левый карман, вы заглянете в один ящик. Потом на стол. И так далее, во всех местах, которые можете придумать. Только после того, как вы исчерпаете все места, вы вернетесь к брюкам и будете искать в следующем кармане.)

**Плюсы:**
*   Этот алгоритм гарантированно находит оптимальное решение.

**Минусы:**
*   Этот алгоритм почти гарантированно работает дольше минимально возможного времени.
*   В худшем случае этот алгоритм занимает максимально возможное время для выполнения.

**Пример кода (удаление узла из очереди):**
```python
def remove(self):
    if self.empty():
        raise Exception("empty frontier")
    else:
        node = self.frontier[0]  # Сохраняем самый старый элемент в списке
        self.frontier = self.frontier[1:]  # Удаляем первый узел
        return node
```

---

### Жадный поиск по первому лучшему совпадению

**Поиск в ширину** и **поиск в глубину** являются **неинформированными** алгоритмами поиска. То есть эти алгоритмы не используют никаких знаний о проблеме, кроме тех, которые они приобрели в процессе собственного исследования. Однако чаще всего некоторое знание о проблеме все же доступно. Например, когда человек, решающий лабиринт, подходит к развилке, он может видеть, какое направление ведет в общем направлении к выходу, а какое — нет. ИИ может делать то же самое. Алгоритм, который использует дополнительные знания для повышения производительности, называется **информированным** алгоритмом поиска.

**Жадный поиск по первому лучшему совпадению (Greedy Best-First Search)** разворачивает узел, который ближе всего к цели, как определяется **эвристической функцией** `h(n)`. Как следует из названия, функция оценивает, насколько следующий узел близок к цели, но она может ошибаться. Эффективность **жадного алгоритма** зависит от того, насколько хороша эвристическая функция. Например, в лабиринте алгоритм может использовать эвристическую функцию, основанную на **манхэттенском расстоянии** между возможными узлами и выходом из лабиринта. **Манхэттенское расстояние** игнорирует стены и подсчитывает, сколько шагов вверх, вниз или в стороны потребуется, чтобы добраться от одного места до цели. Это простая оценка, которую можно вывести на основе координат (x, y) текущего местоположения и местоположения цели.

![image](./.assets/image-1760472840000.png)

Однако важно подчеркнуть, что, как и любая эвристика, она может оказаться ошибочной и направить алгоритм по более медленному пути, чем могло бы быть. Возможно, **неинформированный** алгоритм поиска найдет решение быстрее, но это менее вероятно, чем в случае с **информированным** алгоритмом.

---

### A* Поиск

Развитие **жадного алгоритма**, **A* поиск** учитывает не только `h(n)`, предполагаемую стоимость от текущего местоположения до цели, но и `g(n)`, стоимость, которая была накоплена до текущего местоположения. Объединяя эти два значения, алгоритм получает более точный способ определения стоимости решения и оптимизации своих выборов на ходу. Алгоритм отслеживает (`стоимость пути до сих пор` + `предполагаемая стоимость до цели`), и как только она превышает предполагаемую стоимость какого-либо предыдущего варианта, алгоритм оставляет текущий путь и возвращается к предыдущему варианту, предотвращая тем самым движение по длинному неэффективному пути, который `h(n)` ошибочно пометила как лучший.

Опять же, поскольку этот алгоритм также основан на эвристике, он настолько же хорош, насколько хороша используемая им эвристика. Возможно, в некоторых ситуациях он будет менее эффективен, чем **жадный поиск** или даже **неинформированные** алгоритмы. Чтобы **A* поиск** был оптимальным, эвристическая функция `h(n)` должна быть:

1.  **Допустимой**, то есть никогда *не переоценивать* истинную стоимость.
2.  **Согласованной**, что означает, что оценочная стоимость пути до цели нового узла плюс стоимость перехода к нему от предыдущего узла больше или равна оценочной стоимости пути до цели предыдущего узла. Если выразить в форме уравнения, `h(n)` согласована, если для каждого узла `n` и узла-преемника `n'` со стоимостью шага `c`: `h(n) ≤ h(n') + c`.

---

### Поиск против противника

Если ранее мы обсуждали алгоритмы, которым нужно найти ответ на вопрос, то в **поиске против противника** алгоритм сталкивается с оппонентом, который пытается достичь противоположной цели. Часто ИИ, использующий такой поиск, встречается в играх, таких как крестики-нолики.

### Минимакс

**Минимакс (Minimax)** — это тип алгоритма в поиске против противника, который представляет условия победы как (-1) для одной стороны и (+1) для другой стороны. Дальнейшие действия будут определяться этими условиями: минимизирующая сторона пытается получить наименьший счет, а максимизирующая — наибольший.

Представление ИИ для крестиков-ноликов:

*   **S₀:** Начальное состояние (в нашем случае пустая доска 3x3).
*   **Players(s):** Функция, которая по данному состоянию `s` возвращает, чей сейчас ход (X или O).
*   **Actions(s):** Функция, которая по данному состоянию `s` возвращает все допустимые ходы в этом состоянии (какие клетки свободны на доске).
*   **Result(s, a):** Функция, которая по данному состоянию `s` и действию `a` возвращает новое состояние. Это доска, которая получилась в результате выполнения действия `a` в состоянии `s` (совершения хода в игре).
*   **Terminal(s):** Функция, которая по данному состоянию `s` проверяет, является ли это последним шагом в игре, т.е. выиграл ли кто-то или ничья. Возвращает `True`, если игра окончена, и `False` в противном случае.
*   **Utility(s):** Функция, которая по данному терминальному состоянию `s` возвращает полезность состояния: -1, 0 или 1.

**Как работает алгоритм:**
Рекурсивно алгоритм имитирует все возможные игры, которые могут начаться с текущего состояния и продолжаться до достижения терминального состояния. Каждое терминальное состояние оценивается как (-1), 0 или (+1).

![image](./.assets/image-1760472854276.png)

Зная, чей ход на основе состояния, алгоритм может определить, выберет ли текущий игрок (при оптимальной игре) действие, которое ведет к состоянию с более низким или более высоким значением. Таким образом, чередуя минимизацию и максимизацию, алгоритм создает значения для состояния, которое получилось бы в результате каждого возможного действия. Если говорить конкретнее, можно представить, что максимизирующий игрок на каждом ходу спрашивает: «Если я сделаю этот ход, получится новое состояние. Если минимизирующий игрок будет играть оптимально, какой ход он сделает, чтобы прийти к наименьшему значению?» Однако, чтобы ответить на этот вопрос, максимизирующий игрок должен спросить: «Чтобы знать, что сделает минимизирующий игрок, мне нужно смоделировать тот же процесс в его голове: минимизирующий игрок будет спрашивать: "Если я сделаю этот ход, какой ход может сделать максимизирующий игрок, чтобы прийти к наибольшему значению?"» Это рекурсивный процесс.

![image](./.assets/image-1760472873856.png)

**Псевдокод алгоритма Минимакс:**

*   Для состояния `s`:
    *   Максимизирующий игрок выбирает действие `a` из `Actions(s)`, которое дает наибольшее значение `Min-Value(Result(s, a))`.
    *   Минимизирующий игрок выбирает действие `a` из `Actions(s)`, которое дает наименьшее значение `Max-Value(Result(s, a))`.

*   Функция `Max-Value(state)`:
    *   Установить `v = -∞`
    *   Если `Terminal(state)`: вернуть `Utility(state)`
    *   Для каждого `action` в `Actions(state)`:
        *   `v = Max(v, Min-Value(Result(state, action)))`
    *   Вернуть `v`

*   Функция `Min-Value(state)`:
    *   Установить `v = ∞`
    *   Если `Terminal(state)`: вернуть `Utility(state)`
    *   Для каждого `action` в `Actions(state)`:
        *   `v = Min(v, Max-Value(Result(state, action)))`
    *   Вернуть `v`

---

### Отсечение альфа-бета

**Отсечение альфа-бета (Alpha-Beta Pruning)** — это способ оптимизации **Минимакса**, который пропускает некоторые рекурсивные вычисления, которые заведомо неблагоприятны. После установления значения одного действия, если есть первоначальные свидетельства, что следующее действие может позволить противнику получить лучший результат, чем уже установленное действие, нет необходимости further исследовать это действие, поскольку оно заведомо будет менее благоприятным, чем предыдущее.

**(Пример:** максимизирующий игрок знает, что на следующем шаге минимизатор будет добиваться наименьшего счета. Предположим, у максимизатора есть три возможных действия, и первое оценивается в 4. Затем игрок начинает вычислять значение для следующего действия. Для этого он генерирует значения действий минимизатора, если текущий игрок сделает этот ход, зная, что минимизатор выберет наименьшее. Однако, прежде чем завершить вычисления для всех возможных действий минимизатора, игрок видит, что один из вариантов имеет значение 3. Это означает, что нет причин продолжать исследовать другие возможные действия для минимизатора. Значение еще не оцененного действия не имеет значения, будь то 10 или (-10). Если значение будет 10, минимизатор выберет наименьший вариант, 3, который уже хуже установленного 4. Если же неоцененное действие окажется (-10), минимизатор выберет его, (-10), что еще более невыгодно для максимизатора. Следовательно, вычисление дополнительных возможных действий для минимизатора в этот момент не имеет значения для максимизатора, поскольку у него уже есть заведомо лучший выбор со значением 4.)

![image](./.assets/image-1760472881776.png)

---

### Ограниченный по глубине Минимакс

Всего существует 255 168 возможных игр в крестики-нолики и 10²⁹⁰⁰⁰ возможных игр в шахматы. Алгоритм минимакса, представленный до сих пор, требует генерации всех гипотетических игр с определенного момента до терминального условия. В то время как вычисление всех игр в крестики-нолики не представляет проблемы для современного компьютера, сделать это для шахмат в настоящее время невозможно.

**Ограниченный по глубине Минимакс (Depth-Limited Minimax)** рассматривает только заранее определенное количество ходов, после чего останавливается, так и не дойдя до терминального состояния. Однако это не позволяет получить точное значение для каждого действия, поскольку конец гипотетических игр не достигнут. Чтобы справиться с этой проблемой, **Ограниченный по глубине Минимакс** полагается на **оценочную функцию (evaluation function)**, которая оценивает ожидаемую полезность игры из данного состояния, или, другими словами, присваивает значения состояниям. Например, в шахматной игре оценочная функция принимает на вход текущую конфигурацию доски, пытается оценить ее ожидаемую полезность (на основе того, какие фигуры есть у каждого игрока и их расположения на доске), а затем возвращает положительное или отрицательное значение, которое показывает, насколько благоприятна доска для одного игрока по сравнению с другим. Эти значения можно использовать для принятия решения о правильном действии, и чем лучше оценочная функция, тем лучше алгоритм Минимакса, который на нее полагается.
# Лекция 3 Оптимизация

Оптимизация — это выбор наилучшего варианта из множества возможных вариантов. Мы уже сталкивались с задачами, в которых пытались найти наилучший возможный вариант, например, в алгоритме минимакса, и сегодня мы узнаем об инструментах, которые можно использовать для решения еще более широкого круга задач.

## Локальный поиск

Локальный поиск — это алгоритм поиска, который поддерживает один узел и выполняет поиск, перемещаясь к соседнему узлу. Этот тип алгоритма отличается от тех типов поиска, которые мы видели ранее. Если при решении лабиринта, например, мы хотели найти самый быстрый путь к цели, то локальный поиск заинтересован в поиске наилучшего ответа на вопрос. Часто локальный поиск приводит к ответу, который не является оптимальным, но «достаточно хорош», экономя при этом вычислительные мощности.

Рассмотрим следующий пример задачи локального поиска: у нас есть четыре дома в заданных местах. Мы хотим построить две больницы так, чтобы минимизировать расстояние от каждого дома до больницы. Эту задачу можно визуализировать следующим образом:

![image](./.assets/image-1760905901824.png)

На этой иллюстрации мы видим возможную конфигурацию домов и больниц. Расстояние между ними измеряется с использованием манхэттенского расстояния (количество ходов вверх, вниз и в стороны; более подробно обсуждалось в лекции 0), и сумма расстояний от каждого дома до ближайшей больницы равна 17. Мы называем это **стоимостью** (cost), потому что мы пытаемся минимизировать это расстояние. В данном случае **состоянием** (state) будет любая конфигурация домов и больниц.

![image](./.assets/image-1760905909488.png)

Абстрагируя эту концепцию, мы можем представить каждую конфигурацию домов и больниц в виде ландшафта пространства состояний, показанного ниже. Каждый из столбцов на рисунке представляет значение состояния, которым в нашем примере будет стоимость определенной конфигурации домов и больниц.

Опираясь на эту визуализацию, мы можем определить несколько важных терминов для нашего дальнейшего обсуждения:

- **Целевая функция (Objective Function)** — это функция, которую мы используем для максимизации ценности (value) решения.
- **Функция стоимости (Cost Function)** — это функция, которую мы используем для минимизации стоимости (cost) решения (именно эту функцию мы бы использовали в нашем примере с домами и больницами. Мы хотим минимизировать расстояние от домов до больниц).
- **Текущее состояние (Current State)** — это состояние, которое в данный момент рассматривается функцией.
- **Соседнее состояние (Neighbor State)** — это состояние, в которое текущее состояние может перейти. В одномерном ландшафте пространства состояний выше соседним состоянием является состояние по обе стороны от текущего. В нашем примере соседним состоянием может быть состояние, полученное в результате перемещения одной из больниц в любом направлении на один шаг. Соседние состояния обычно похожи на текущее состояние, и, следовательно, их значения близки к значению текущего состояния.

Обратите внимание, что алгоритмы локального поиска работают, рассматривая один узел (текущее состояние), а затем перемещаясь к одному из соседей текущего состояния. Это отличается, например, от алгоритма минимакса, где каждое состояние в пространстве состояний рассматривалось рекурсивно.

## Подъем на холм

Подъем на холм — это один из видов алгоритма локального поиска. В этом алгоритме соседние состояния сравниваются с текущим, и если какое-либо из них лучше, мы переходим из текущего состояния в это соседнее состояние. Что считается «лучше», определяется тем, используем ли мы целевую функцию (предпочитая большее значение) или функцию стоимости (предпочитая меньшее значение).

Алгоритм подъема на холм будет выглядеть следующим образом в псевдокоде:

```
функция Подъем-На-Холм(problem):
  current = начальное состояние problem
  повторять:
    neighbor = сосед current с наилучшим значением
    если neighbor не лучше, чем current:
      вернуть current
    current = neighbor
```

В этом алгоритме мы начинаем с текущего состояния. В некоторых задачах мы будем знать, каково текущее состояние, в то время как в других нам придется начать со случайного выбора. Затем мы повторяем следующие действия: оцениваем соседей, выбирая того, у которого наилучшее значение. Затем мы сравниваем значение этого соседа со значением текущего состояния. Если сосед лучше, мы переключаем текущее состояние на состояние соседа, а затем повторяем процесс. Процесс заканчивается, когда мы сравниваем лучшего соседа с текущим состоянием, и текущее состояние оказывается лучше. Тогда мы возвращаем текущее состояние.

Используя алгоритм подъема на холм, мы можем начать улучшать местоположения, которые мы назначили больницам в нашем примере. После нескольких переходов мы приходим к следующему состоянию:

![image](./.assets/image-1760905930811.png)

В этом состоянии стоимость равна 11, что является улучшением по сравнению с 17, стоимостью начального состояния. Однако это еще не оптимальное состояние. Например, перемещение больницы слева под верхний левый дом привело бы к стоимости 9, что лучше, чем 11. Однако эта версия алгоритма подъема на холм не может туда добраться, потому что все соседние состояния имеют по крайней мере такую же стоимость, как и текущее. В этом смысле алгоритм подъема на холм «недальновиден», часто останавливаясь на решениях, которые *лучше* некоторых других, но не обязательно *наилучшие* из всех возможных.

## Локальные и глобальные минимумы и максимумы

Как упоминалось выше, алгоритм подъема на холм может застрять в локальных максимумах или минимумах.

- **Локальный максимум** (plural: maxima) — это состояние, которое имеет более высокое значение, чем его **соседние состояния**. В противовес этому, **глобальный максимум** — это состояние, которое имеет самое высокое значение из **всех состояний** в пространстве состояний.
  
![image](./.assets/image-1760905976849.png)

- **Локальный минимум** (plural: minima) — это состояние, которое имеет более низкое значение, чем его **соседние состояния**. В противовес этому, **глобальный минимум** — это состояние, которое имеет самое низкое значение из **всех состояний** в пространстве состояний.

![image](./.assets/image-1760905985771.png)

Проблема алгоритмов подъема на холм в том, что они могут остановиться в локальных минимумах и максимумах. Как только алгоритм достигает точки, соседи которой хуже (для цели функции), чем текущее состояние, алгоритм останавливается.

Особые типы локальных максимумов и минимумов включают **плоский локальный максимум/минимум** (плато), где несколько состояний с одинаковым значением соседствуют, образуя плато, соседи которого имеют худшее значение, и **«плечо» (shoulder)**, где несколько состояний с одинаковым значением соседствуют, а соседи плато могут быть как лучше, так и хуже. Начиная с середины плато, алгоритм не сможет продвинуться ни в одном направлении.

![image](./.assets/image-1760905992187.png)

## Варианты подъема на холм

Из-за ограничений подъема на холм было придумано несколько вариантов для преодоления проблемы застревания в локальных минимумах и максимумах. Общим для всех вариантов алгоритма является то, что, независимо от стратегии, каждый из них все еще имеет потенциал остановиться в локальных минимумах и максимумах и не имеет средств для продолжения оптимизации. Приведенные ниже алгоритмы сформулированы так, как будто большее значение — это лучше, но они также применимы к функциям стоимости, где целью является минимизация затрат.

- **Крутой подъем (Steepest-ascent):** выбор соседа с самым высоким значением. Это стандартный вариант, который мы обсуждали выше.
- **Стохастический (Stochastic):** случайный выбор из соседей с более высоким значением. Делая это, мы выбираем движение в любом направлении, которое улучшает наше значение. Это имеет смысл, если, например, сосед с самым высоким значением ведет к локальному максимуму, в то время как другой сосед ведет к глобальному максимуму.
- **Первый подошедший (First-choice):** выбор первого соседа с более высоким значением.
- **Случайный перезапуск (Random-restart):** выполнение подъема на холм несколько раз. Каждый раз, начиная со случайного состояния. Сравнить максимумы каждой попытки и выбрать самый высокий из них.
- **Локальный лучевой поиск (Local Beam Search):** выбирает $k$ соседей с самыми высокими значениями. Это отличает его от большинства алгоритмов локального поиска тем, что он использует несколько узлов для поиска, а не только один.

Хотя алгоритмы локального поиска не всегда дают наилучшее возможное решение, они часто могут дать достаточно хорошее решение в ситуациях, когда рассмотрение каждого возможного состояния вычислительно невозможно.

## Имитация отжига

Хотя мы рассмотрели варианты, которые могут улучшить подъем на холм, у всех у них есть один и тот же недостаток: как только алгоритм достигает локального максимума, он прекращает работу. Имитация отжига позволяет алгоритму «вырваться», если он застрял в локальном максимуме.

Отжиг — это процесс нагрева металла и его медленного охлаждения, который служит для упрочнения металла. Это используется как метафора для алгоритма имитации отжига, который начинается с высокой «температуры», будучи более склонным принимать случайные решения, и, по мере снижения температуры, он становится менее склонным принимать случайные решения, становясь более «устойчивым». Этот механизм позволяет алгоритму изменять свое состояние на соседа, который *хуже* текущего состояния, благодаря чему он может выходить из локальных максимумов.

Ниже приведен псевдокод для имитации отжига:

```
функция Имитация-Отжига(problem, max):
  current = начальное состояние problem
  для t от 1 до max:
    T = Температура(t)
    neighbor = случайный сосед current
    ΔE = насколько neighbor лучше, чем current
    если ΔE > 0:
      current = neighbor
    с вероятностью e^(ΔE/T) установленный current = сосед
  вернуть current
```

Алгоритм берет на вход задачу и *максимальное* количество раз, когда она должна повториться. Для каждой итерации *T* задается с помощью функции Temperature. Эта функция возвращает более высокое значение на ранних итерациях (когда *t* низкое) и меньшее значение на более поздних итерациях (когда *t* высокое). Затем выбирается случайный сосед, и *ΔE* вычисляется таким образом, что он количественно определяет, насколько состояние соседа лучше текущего состояния. Если состояние соседа лучше текущего состояния (*ΔE* > 0), как и раньше, мы устанавливаем текущее состояние как состояние соседа. Однако, когда состояние соседа хуже (*ΔE* < 0), мы все еще можем установить наше текущее состояние как это соседнее состояние, и мы делаем это с вероятностью e^(*ΔE/T*). Идея здесь заключается в том, что более отрицательное *ΔE* приведет к меньшей вероятности выбора соседнего состояния, и чем выше температура *T*, тем выше вероятность того, что будет выбрано соседнее состояние. Это означает, что чем хуже состояние соседа, тем меньше вероятность его выбора, и чем раньше алгоритм находится в своем процессе, тем больше вероятность того, что он установит худшее состояние соседа в качестве текущего состояния. Математика этого выглядит следующим образом: e — константа (около 2,72), а *ΔE* — отрицательное (поскольку этот сосед хуже текущего состояния). Чем больше отрицательное *ΔE,* тем ближе результирующее значение к 0. Чем выше температура *T*, тем *ближе ΔE/T* к 0, что делает вероятность ближе к 1.

## Задача коммивояжера

В задаче коммивояжера задача состоит в том, чтобы соединить все точки, выбрав кратчайшее возможное расстояние. Это, например, то, что должны делать компании по доставке: найти кратчайший маршрут от магазина до домов всех клиентов и обратно.

![image](./.assets/image-1760906007487.png)

В этом случае соседнее состояние можно рассматривать как состояние, в котором две стрелки меняются местами. Вычисление каждой возможной комбинации делает эту задачу вычислительно сложной (всего 10 точек дают нам 10!, или 3 628 800 возможных маршрутов). Используя алгоритм имитации отжига, можно найти хорошее решение с меньшими вычислительными затратами.

## Линейное программирование

Линейное программирование — это семейство задач, которые оптимизируют линейное уравнение (уравнение вида y = ax₁ + bx₂ + …).

Линейное программирование будет состоять из следующих компонентов:

Функция стоимости, которую мы хотим минимизировать: c₁x₁ + c₂x₂ + ... + cnxn. Здесь каждый x₋ является переменной и связан с некоторой стоимостью c₋.

Ограничение, представленное в виде суммы переменных, которое либо меньше, либо равно значению (a₁x₁ + a₂x₂ + ... + anxn ≤ b) или точно равно этому значению (a₁x₁ + a₂x₂ + ... + anxn = b). В этом случае x₋ — это переменная, а a₋ — это некоторый ресурс, связанный с ней, а b — сколько ресурсов мы можем выделить на решение этой задачи.

Индивидуальные границы переменных (например, что переменная не может быть отрицательной) вида li ≤ xi ≤ ui.

Рассмотрим следующий пример:

Две машины, X₁ и X₂. X₁ стоит $50 в час за запуск, X₂ Запуск стоит 80 долларов в час. Цель состоит в том, чтобы свести к минимуму затраты. Это можно формализовать в виде функции стоимости: 50x₁ + 80x₂.

X₁ требует 5 единиц труда в час. X₂ требуется 2 единиц труда в час. Всего 20 единиц труда для тратить. Это можно формализовать в виде ограничения: 5x₁ + 2x₂ ≤ 20.

X₁ производит 10 единиц продукции в час. X₂ производит 12 единиц производительности в час. Компании необходимо 90 единиц выхода. Это еще одно ограничение. Дословно его можно переписать как 10x₁ + 12x₂ ≥ 90. Тем не менее, ограничения должны иметь вид (a₁x₁ + a₂x₂ + ... + anxn ≤ b) или (a₁x₁ + a₂x₂ + ... + anxn = b). Следовательно, мы умножаем на (-1), чтобы получить эквивалентное уравнение нужного вида: (-10x₁) + (-12x₂) ≤ -90.

Оптимизирующий алгоритм для линейного программирования требует базовых знаний в геометрии и линейной алгебре, которые мы не хотим предполагать. Вместо этого мы можем использовать уже существующие алгоритмы, такие как Симплекс (Simplex) и Метод внутренних точек (Interior-Point).

Ниже приведен пример линейного программирования, использующий библиотеку scipy в Python:

```python
import scipy.optimize

# Целевая функция: 50x_1 + 80x_2
# Ограничение 1: 5x_1 + 2x_2 <= 20
# Ограничение 2: -10x_1 + -12x_2 <= -90

result = scipy.optimize.linprog(
    [50, 80],  # Функция стоимости: 50x_1 + 80x_2
    A_ub=[[5, 2], [-10, -12]],  # Коэффициенты для неравенств
    b_ub=[20, -90],  # Ограничения для неравенств: 20 и -90
)

if result.success:
    print(f"X1: {round(result.x[0], 2)} часов")
    print(f"X2: {round(result.x[1], 2)} часов")
else:
    print("Нет решения")
```

## Удовлетворение ограничений

Задачи удовлетворения ограничений (Constraint Satisfaction problems) — это класс задач, в которых переменным необходимо присвоить значения, удовлетворяя при этом некоторым условиям.

Задачи удовлетворения ограничений имеют следующие свойства:

- Набор переменных (x₁, x₂, ..., xn)
- Набор доменов для каждой переменной {D₁, D₂, ..., Dn}
- Набор ограничений C

Судоку можно представить как задачу удовлетворения ограничений, где каждая пустая клетка — это переменная, домен — числа 1-9, а ограничения — это клетки, которые не могут быть равны друг другу.

Рассмотрим другой пример. Каждый из 4 студентов проходит три курса из A, B, ..., G. По каждому курсу должен быть экзамен, и возможные дни для экзаменов — понедельник, вторник и среда. Однако один и тот же студент не может сдавать два экзамена в один день. В этом случае переменные — это курсы, домен — это дни, а ограничения — это то, какие курсы не могут быть назначены на экзамен в один и тот же день, потому что их проходит один и тот же студент.

![image](./.assets/image-1760907116728.png)

Эту задачу можно решить, используя ограничения, представленные в виде графа. Каждый узел на графе — это курс, а ребро проводится между двумя курсами, если их нельзя запланировать на один и тот же день.

![image](./.assets/image-1760907127338.png)

Еще несколько терминов, которые стоит знать о задачах удовлетворения ограничений:

- **Жесткое ограничение (Hard Constraint)** — это ограничение, которое должно быть удовлетворено в правильном решении.
- **Мягкое ограничение (Soft Constraint)** — это ограничение, которое выражает, какое решение предпочтительнее других.
- **Унарное ограничение (Unary Constraint)** — это ограничение, которое затрагивает только одну переменную. В нашем примере унарным ограничением было бы утверждение, что курс A не может иметь экзамен в понедельник {A ≠ Понедельник}.
- **Бинарное ограничение (Binary Constraint)** — это ограничение, которое затрагивает две переменные. Это тот тип ограничения, который мы использовали в примере выше, говоря, что какие-то два курса не могут иметь одинаковое значение {A ≠ B}.

### Согласованность узла

Согласованность узла (Node consistency) — это когда все значения в домене переменной удовлетворяют унарным ограничениям этой переменной.

Например, возьмем два курса, A и B. Домен для каждого курса — {Понедельник, Вторник, Среда}, а ограничения: {*A ≠ Пн, В ≠ Вт, В ≠ Пн, А ≠ В*}.
Сейчас ни A, ни B не являются согласованными, потому что существующие ограничения не позволяют им принять каждое значение, которое есть в их домене. Однако, если мы удалим Понедельник из домена A, он станет согласованным по узлу. Чтобы достичь согласованности узла B, нам придется удалить из его домена и Понедельник, и Вторник.

### Согласованность дуг

Согласованность дуг (Arc consistency) — это когда все значения в домене переменной удовлетворяют бинарным ограничениям этой переменной (обратите внимание, что мы теперь используем «дуга» (arc) для обозначения того, что ранее называли «ребром» (edge)). Другими словами, чтобы сделать X согласованным по дуге относительно Y, удаляйте элементы из домена X до тех пор, пока для каждого выбора X не найдется возможный выбор для Y.

Рассмотрим наш предыдущий пример с пересмотренными доменами: A:{Вторник, Среда} и B:{Среда}. Чтобы A был согласован по дуге с B, независимо от того, на какой день назначен экзамен A (из его домена), B все равно должен иметь возможность назначить экзамен. Является ли A согласованным по дуге с B? Если A принимает значение Вторник, то B может принять значение Среда. Однако, если A принимает значение Среда, то нет значения, которое B мог бы принять (помните, что одно из ограничений — A $\ne$ B). Следовательно, A не согласован по дуге с B. Чтобы это изменить, мы можем удалить Среду из домена A. Тогда любое значение, которое принимает A (Вторник — единственный вариант), оставляет значение для B (Среда). Теперь A согласован по дуге с B.

Давайте посмотрим на алгоритм в псевдокоде, который делает переменную согласованной по дуге относительно какой-либо другой переменной (обратите внимание, что csp означает «задача удовлетворения ограничений»).

```
функция Revise(csp, X, Y):
  revised = false
  для x в X.domain:
    если ни один y в Y.domain не удовлетворяет ограничению для (X,Y):
      удалить x из X.domain
      revised = true
  вернуть revised
```

Этот алгоритм начинает с отслеживания, было ли внесено какое-либо изменение в домен X, используя переменную *revised*. Это будет полезно в следующем алгоритме, который мы рассмотрим. Затем код повторяется для каждого значения в домене X и проверяет, есть ли у Y значение, удовлетворяющее ограничениям. Если да, то ничего не делать, если нет — удалить это значение из домена X.

Часто нас интересует приведение всей задачи к согласованности дуг, а не только одной переменной относительно другой. В этом случае мы будем использовать алгоритм под названием AC-3, который использует Revise:

```
функция AC-3(csp):
  queue = все дуги в csp
  пока queue не пуста:
    (X, Y) = Dequeue(queue)
    если Revise(csp, X, Y):
      если размер X.domain == 0:
        вернуть false
      для каждого Z в X.neighbors - {Y}:
        Enqueue(queue, (Z,X))
  вернуть true
```

Этот алгоритм добавляет все дуги в задаче в очередь. Каждый раз, когда он рассматривает дугу, он удаляет ее из очереди. Затем он запускает алгоритм Revise, чтобы проверить, согласована ли эта дуга. Если были внесены изменения для ее согласования, требуются дальнейшие действия. Если результирующий домен X пуст, это означает, что эта задача удовлетворения ограничений нерешаема (поскольку нет значений, которые X может принять, чтобы Y мог принять какое-либо значение, учитывая ограничения). Если на предыдущем шаге задача не была признана нерешаемой, то, поскольку домен X был изменен, нам нужно проверить, остаются ли согласованными все дуги, связанные с X. То есть мы берем всех соседей X, кроме Y, и добавляем дуги между ними и X в очередь. Однако, если алгоритм Revise возвращает false, что означает, что домен не был изменен, мы просто продолжаем рассматривать другие дуги.

Хотя алгоритм согласованности дуг может упростить задачу, он не обязательно ее решит, поскольку он рассматривает только бинарные ограничения, а не то, как могут быть взаимосвязаны несколько узлов. Наш предыдущий пример, где каждый из 4 студентов проходит 3 курса, остается неизменным после запуска AC-3 на нем.

Мы сталкивались с задачами поиска в нашей первой лекции. Задачу удовлетворения ограничений можно рассматривать как задачу поиска:

- Начальное состояние: пустое присваивание (ни одной переменной не присвоено никакое значение).
- Действия: добавить {переменная = значение} к присваиванию; то есть, дать некоторой переменной значение.
- Модель перехода: показывает, как добавление присваивания изменяет присваивание. Здесь нет большой глубины: модель перехода возвращает состояние, которое включает присваивание после последнего действия.
- Проверка цели: проверить, всем ли переменным присвоено значение и все ли ограничения удовлетворены.
- Функция стоимости пути: все пути имеют одинаковую стоимость. Как мы упоминали ранее, в отличие от типичных задач поиска, задачи оптимизации заботятся о решении, а не о пути к нему.

Однако, подходить к задаче удовлетворения ограничений наивно, как к обычной задаче поиска, крайне неэффективно. Вместо этого мы можем использовать структуру задачи удовлетворения ограничений, чтобы решить ее более эффективно.

## Поиск с возвратом

Поиск с возвратом (Backtracking search) — это тип алгоритма поиска, который учитывает структуру задачи поиска с удовлетворением ограничений. В общем, это рекурсивная функция, которая пытается продолжать присваивать значения до тех пор, пока они удовлетворяют ограничениям. Если ограничения нарушаются, она пробует другое присваивание. Давайте посмотрим на псевдокод для него:

```
функция Backtrack(assignment, csp):
  если assignment завершено:
    вернуть assignment
  var = Select-Unassigned-Var(assignment, csp)
  для value в Domain-Values(var, assignment, csp):
    если value согласуется с assignment:
      добавить {var = value} в assignment
      result = Backtrack(assignment, csp)
      если result ≠ failure:
        вернуть result
      удалить {var = value} из assignment
  вернуть failure
```

Словесно, этот алгоритм начинает с возврата текущего присваивания, если оно завершено. Это означает, что, если алгоритм закончил, он не будет выполнять никаких дополнительных действий. Вместо этого он просто вернет завершенное присваивание. Если присваивание не завершено, алгоритм выбирает любую из переменных, у которой еще нет присваивания. Затем алгоритм пытается присвоить значение переменной и снова запускает алгоритм Backtrack для результирующего присваивания (рекурсия). Затем он проверяет результирующее значение. Если это не *failure* (неудача), это означает, что присваивание сработало, и он должен вернуть это присваивание. Если результирующее значение — *failure*, то последнее присваивание удаляется, и предпринимается попытка присвоить новое возможное значение, повторяя тот же процесс. Если все возможные значения в домене вернули *failure*, это означает, что нам нужно выполнить возврат (backtrack). То есть, проблема в каком-то предыдущем присваивании. Если это происходит с переменной, с которой мы начали, это означает, что никакое решение не удовлетворяет ограничениям.

Рассмотрим следующий ход действий:

![image](./.assets/image-1760907215379.png)

Мы начинаем с пустых присваиваний (вверху слева). Затем мы выбираем переменную A и присваиваем ей какое-то значение, Понедельник (вверху справа). Затем, используя это присваивание, мы запускаем алгоритм снова. Теперь, когда у A уже есть присваивание, алгоритм рассмотрит B и присвоит ему Понедельник (внизу слева). Это присваивание возвращает false, поэтому вместо присвоения значения C при данном предыдущем присваивании, алгоритм попытается присвоить новое значение B, Вторник (внизу справа). Это новое присваивание удовлетворяет ограничениям, и следующей будет рассмотрена новая переменная при данном присваивании. Если, например, присваивание B также Вторника или Среды привело бы к неудаче, то алгоритм выполнил бы возврат и вернулся к рассмотрению A, присвоив ему другое значение, Вторник. Если и Вторник, и Среда также вернут *failure*, это означает, что мы перепробовали все возможные присваивания, и задача нерешаема.

В разделе с исходным кодом вы можете найти реализацию алгоритма поиска с возвратом с нуля. Однако этот алгоритм широко используется, и поэтому множество библиотек уже содержат его реализацию.

## Логический вывод

Хотя поиск с возвратом более эффективен, чем простой поиск, он все равно требует больших вычислительных мощностей. Обеспечение согласованности дуг, с другой стороны, менее ресурсоемко. Чередуя поиск с возвратом с логическим выводом (обеспечением согласованности дуг), мы можем получить более эффективный алгоритм. Этот алгоритм называется алгоритмом **Поддержания Согласованности Дуг (Maintaining Arc-Consistency)**. Этот алгоритм будет обеспечивать согласованность дуг после каждого нового присваивания в поиске с возвратом. Конкретно, после того как мы сделаем новое присваивание для X, мы вызовем алгоритм AC-3 и запустим его с очередью из всех дуг (Y,X), где Y — сосед X (а не с очередью из всех дуг в задаче). Ниже приведен пересмотренный алгоритм Backtrack, который поддерживает согласованность дуг, с новыми дополнениями, выделенными **жирным шрифтом**.

```
функция Backtrack(assignment, csp):
  если assignment завершено:
    вернуть assignment
  var = Select-Unassigned-Var(assignment, csp)
  для value в Domain-Values(var, assignment, csp):
    если value согласуется с assignment:
      добавить {var = value} в assignment
      **inferences = Inference(assignment, csp)**
      **если inferences ≠ failure:**
        **добавить inferences в assignment**
        result = Backtrack(assignment, csp)
        если result ≠ failure:
          вернуть result
      **удалить {var = value} и inferences из assignment**
  вернуть failure
```

Функция *Inference* (Логический вывод) запускает алгоритм AC-3, как описано. Ее вывод — это все логические выводы, которые можно сделать посредством обеспечения согласованности дуг. Буквально, это новые присваивания, которые можно вывести из предыдущих присваиваний и структуры задачи удовлетворения ограничений.

Существуют дополнительные способы сделать алгоритм более эффективным. До сих пор мы выбирали неприсвоенную переменную случайным образом. Однако некоторые выборы с большей вероятностью приведут к решению быстрее, чем другие. Это требует использования эвристик. Эвристика — это эмпирическое правило, означающее, что чаще всего она приведет к лучшему результату, чем следование наивному подходу, но это не гарантировано.

Эвристика **Минимум оставшихся значений (Minimum Remaining Values, MRV)** — одна из таких. Идея здесь в том, что если домен переменной был сужен логическим выводом, и теперь у нее осталось только одно значение (или даже два), то, сделав это присваивание, мы уменьшим количество возвратов, которые нам, возможно, придется сделать позже. То есть, нам придется сделать это присваивание рано или поздно, так как оно выводится из обеспечения согласованности дуг. Если это присваивание приведет к неудаче, лучше узнать об этом как можно скорее, а не возвращаться назад позже.

![image](./.assets/image-1760907336090.png)

Например, сузив домены переменных при текущем присваивании, используя эвристику MRV, мы выберем следующей переменную C и присвоим ей значение Среда.

Эвристика **Степени (Degree)** полагается на степени переменных, где степень — это то, сколько дуг соединяют переменную с другими переменными. Выбирая переменную с наивысшей степенью, одним присваиванием мы накладываем ограничения на множество других переменных, ускоряя процесс работы алгоритма.

![image](./.assets/image-1760907344561.png)

Например, все переменные выше имеют домены одинакового размера. Таким образом, мы должны выбрать переменную с наивысшей степенью, коей будет переменная E.

Обе эвристики не всегда применимы. Например, когда несколько переменных имеют одинаковое наименьшее количество значений в своем домене, или когда несколько переменных имеют одинаковую наивысшую степень.

Еще один способ сделать алгоритм более эффективным — применить еще одну эвристику, когда мы выбираем значение из домена переменной. Здесь мы хотели бы использовать эвристику **Наименее ограничивающих значений (Least Constraining Values)**, где мы выбираем значение, которое наложит ограничения на наименьшее число других переменных. Идея здесь в том, что, в то время как в эвристике степени мы хотели использовать переменную, которая с большей вероятностью ограничит другие переменные, здесь мы хотим, чтобы эта переменная накладывала наименьшие ограничения на другие переменные. То есть, мы хотим найти то, что может быть самым большим потенциальным источником проблем (переменная с наивысшей степенью), а затем сделать ее наименее проблемной, насколько это возможно (присвоить ей наименее ограничивающее значение).

![image](./.assets/image-1760907351536.png)

Например, рассмотрим переменную C. Если мы присвоим ей Вторник, мы наложим ограничение на все B, E и F. Однако, если мы выберем Среду, мы наложим ограничение только на B и E. Следовательно, вероятно, лучше выбрать Среду.

## Итог

Подводя итог, задачи оптимизации можно сформулировать множеством способов. Сегодня мы рассмотрели локальный поиск, линейное программирование и удовлетворение ограничений.
# Лекция 2 Неопределённость

На прошлой лекции мы обсуждали, как ИИ может представлять знания и выводить новые. Однако зачастую в реальности ИИ обладает лишь частичными знаниями о мире, что оставляет место для неопределенности. Тем не менее, мы хотим, чтобы наш ИИ принимал наилучшие возможные решения в таких ситуациях. Например, прогнозируя погоду, ИИ имеет информацию о погоде сегодня, но невозможно со 100% точностью предсказать погоду на завтра. Тем не менее, мы можем справиться лучше, чем просто угадывая, и сегодняшняя лекция посвящена тому, как мы можем создавать ИИ, который принимает оптимальные решения в условиях ограниченной информации и неопределенности.

**Вероятность**

Неопределенность можно представить в виде набора событий и вероятности (шанса) наступления каждого из них.

**Возможные миры**

Каждую возможную ситуацию можно рассматривать как «мир», обозначаемый строчной греческой буквой омега ω. Например, бросок игральной кости может привести к шести возможным мирам: миру, где выпала единица, миру, где выпала двойка, и так далее. Для обозначения вероятности определенного мира мы пишем P(ω).

**Аксиомы теории вероятностей**

*   **0 ≤ P(ω) ≤ 1:** любое значение, представляющее вероятность, должно находиться в диапазоне от 0 до 1.
    *   Ноль означает невозможное событие, например, выпадение 7 на стандартной игральной кости.
    *   Единица означает событие, которое произойдет точно, например, выпадение значения меньше 10 на стандартной игральной кости.
    *   В общем случае, чем выше значение, тем более вероятно событие.
*   Сумма вероятностей всех возможных событий равна 1.

![image](./.assets/image-1760818720222.png)

**Суммирование вероятностей**

Вероятность выпадения числа R на стандартной кости можно представить как P(R). В нашем случае P(R) = 1/6, потому что существует шесть возможных миров (выпадение любого числа от 1 до 6), и каждый из них равновероятен. Теперь рассмотрим событие — бросок двух костей. Теперь существует 36 возможных событий, которые также равновероятны.

![image](./.assets/image-1760818739164.png)

**36 событий**

Однако что будет, если мы попытаемся предсказать сумму двух костей? В этом случае у нас есть только 11 возможных значений (сумма должна быть в диапазоне от 2 до 12), и они выпадают не одинаково часто.

![image](./.assets/image-1760818743759.png)

**Сумма двух костей**

Чтобы получить вероятность события, мы делим количество миров, в которых оно происходит, на общее количество возможных миров. Например, при броске двух костей существует 36 возможных миров. Только в одном из этих миров, когда на обеих костях выпадает 6, мы получаем сумму 12. Таким образом, P(12) = 1/36, или, словами, вероятность броска двух костей с суммой 12 равна 1/36. Чему равна P(7)? Мы подсчитываем и видим, что сумма 7 встречается в 6 мирах. Таким образом, P(7) = 6/36 = 1/6.

**Безусловная вероятность**

Безусловная вероятность — это степень уверенности в предположении при отсутствии каких-либо других свидетельств. Все вопросы, которые мы задавали до сих пор, касались безусловной вероятности, потому что результат броска кости не зависит от предыдущих событий.

**Условная вероятность**

Условная вероятность — это степень уверенности в предположении при наличии некоторых уже известных свидетельств. Как обсуждалось во введении, ИИ может использовать частичную информацию для обоснованных предположений о будущем. Чтобы использовать эту информацию, которая влияет на вероятность будущего события, мы полагаемся на условную вероятность.

Условная вероятность выражается следующей записью: P(a | b), что означает «вероятность наступления события a при условии, что мы знаем, что событие b уже произошло», или, короче, «вероятность a при условии b». Теперь мы можем задавать вопросы, такие как «какова вероятность дождя сегодня при условии, что вчера шел дождь P(дождь сегодня | дождь вчера)» или «какова вероятность того, что у пациента есть болезнь, при данных результатах анализов P(болезнь | результаты анализов)».

Математически, для вычисления условной вероятности a при условии b мы используем следующую формулу:

![image](./.assets/image-1760818758688.png)

**Формула условной вероятности**
`P(a | b) = P(a ∧ b) / P(b)`

Если выразить словами: вероятность того, что a истинно при условии b, равна вероятности того, что и a, и b истинны, деленной на вероятность b. Интуитивно это можно представить так: «нас интересуют события, где и a, и b истинны (числитель), но только среди миров, где мы знаем, что b истинно (знаменатель)». Деление на P(b) ограничивает возможные миры только теми, где b истинно. Следующие формы алгебраически эквивалентны приведенной выше формуле:

**Эквивалентные формулы**
`P(a ∧ b) = P(b) P(a | b)`
`P(a ∧ b) = P(a) P(b | a)`

![image](./.assets/image-1760818768472.png)

Например, рассмотрим P(сумма 12 | на одной кости выпало 6), то есть вероятность того, что при броске двух костей сумма будет двенадцать, при условии, что мы уже бросили одну кость и получили шестерку. Чтобы вычислить это, мы сначала ограничиваем наши миры теми, где значение первой кости равно шести:

![image](./.assets/image-1760818781192.png)

**Ограничение миров**

Теперь мы спрашиваем, сколько раз событие a (сумма равна 12) происходит в мирах, которые мы ограничили (деля на P(b), или вероятность выпадения 6 на первой кости).

**Обусловленная вероятность**

![image](./.assets/image-1760818785064.png)

`P(сумма 12 | первая кость = 6) = P(сумма 12 ∧ первая кость = 6) / P(первая кость = 6) = (1/36) / (1/6) = 1/6`

**Случайные величины**

Случайная величина — это переменная в теории вероятностей, которая имеет область возможных значений, которые она может принимать. Например, для представления возможных исходов броска кости мы можем определить случайную величину Бросок, которая может принимать значения {1, 2, 3, 4, 5, 6}. Чтобы представить статус рейса, мы можем определить переменную Рейс, которая принимает значения {по расписанию, задержан, отменен}.

Часто нас интересует вероятность, с которой каждое значение происходит. Мы представляем это с помощью распределения вероятностей. Например:

*   P(Рейс = по расписанию) = 0.6
*   P(Рейс = задержан) = 0.3
*   P(Рейс = отменен) = 0.1

Если интерпретировать распределение вероятностей словами, это означает, что существует 60% шанс, что рейс будет по расписанию, 30% шанс задержки и 10% шанс отмены. Обратите внимание, что, как показано ранее, сумма вероятностей всех возможных исходов равна 1.

Распределение вероятностей можно представить более сжато в виде вектора. Например, P(Рейс) = <0.6, 0.3, 0.1>. Для интерпретации этой записи значения должны иметь установленный порядок (в нашем случае: по расписанию, задержан, отменен).

**Независимость**

Независимость — это знание того, что наступление одного события не влияет на вероятность другого события. Например, при броске двух костей результат каждой кости независим от другой. Выпадение 4 на первой кости не влияет на значение второй кости. Это противоположно зависимым событиям, например, облачности утром и дождю днем. Если утром облачно, более вероятно, что днем пойдет дождь, поэтому эти события зависимы.

Независимость можно определить математически: события a и b независимы тогда и только тогда, когда вероятность a и b равна вероятности a, умноженной на вероятность b: `P(a ∧ b) = P(a) P(b)`.

**Правило Байеса**

Правило Байеса обычно используется в теории вероятностей для вычисления условной вероятности. Словами правило Байеса гласит, что вероятность b при условии a равна вероятности a при условии b, умноженной на вероятность b и деленной на вероятность a.

**Правило Байеса

![image](./.assets/image-1760818793909.png)

`P(b | a) = P(a | b) P(b) / P(a)`

Например, мы хотим вычислить вероятность дождя днем при условии облачности утром, то есть P(дождь | облака). У нас есть следующая информация:

*   80% дождливых дней начинаются с облачного утра, или P(облака | дождь).
*   40% дней имеют облачное утро, или P(облака).
*   10% дней имеют дождливый полдень, или P(дождь).

Применяя правило Байеса, мы вычисляем (0.1 * 0.8) / 0.4 = 0.2. То есть вероятность дождя днем при условии облачности утром составляет 20%.

Знание P(a | b) в дополнение к P(a) и P(b) позволяет нам вычислить P(b | a). Это полезно, потому что знание условной вероятности видимого эффекта при неизвестной причине, P(видимый эффект | неизвестная причина), позволяет вычислить вероятность неизвестной причины при данном видимом эффекте, P(неизвестная причина | видимый эффект). Например, мы можем изучить P(результаты анализа | болезнь) в медицинских испытаниях, где мы тестируем людей с болезнью и смотрим, как часто анализ ее выявляет. Зная это, мы можем вычислить P(болезнь | результаты анализа), что является ценной диагностической информацией.

**Совместная вероятность**

Совместная вероятность — это вероятность того, что несколько событий произойдут одновременно.

Рассмотрим следующий пример, касающийся вероятностей облачности утром и дождя днем.

Сначала рассмотрим вероятности по отдельности:
*   C = облака: 0.4
*   C = ¬облака: 0.6
*   R = дождь: 0.1
*   R = ¬дождь: 0.9

Глядя на эти данные, мы не можем сказать, связаны ли утренние облака с вероятностью дождя днем. Чтобы это сделать, нам нужно посмотреть на совместные вероятности всех возможных исходов двух переменных. Мы можем представить это в таблице:

| | R = дождь | R = ¬дождь |
| :--- | :--- | :--- |
| **C = облака** | 0.08 | 0.32 |
| **C = ¬облака** | 0.02 | 0.58 |

Теперь мы можем получить информацию о совместном появлении событий. Например, мы знаем, что вероятность того, что в определенный день утром будут облака, а днем дождь, равна 0.08. Вероятность отсутствия облаков утром и отсутствия дождя днем равна 0.58.

Используя совместные вероятности, мы можем вывести условную вероятность. Например, нас интересует распределение вероятностей облачности утром при условии дождя днем. P(C | дождь) = P(C, дождь) / P(дождь) (примечание: в теории вероятностей запятая и ∧ используются как синонимы). Таким образом, P(C, дождь) = P(C ∧ дождь). Словами: мы делим совместную вероятность дождя и облаков на вероятность дождя.

В последнем уравнении P(дождь) можно рассматривать как константу, на которую умножается P(C, дождь). Таким образом, мы можем переписать P(C, дождь) / P(дождь) = α * P(C, дождь), или α<0.08, 0.02>. Вынесение α оставляет нам пропорции вероятностей возможных значений C при условии дождя днем. А именно, если днем есть дождь, то пропорция вероятностей облаков утром и отсутствия облаков утром составляет 0.08 : 0.02. Обратите внимание, что 0.08 и 0.02 в сумме не дают 1; однако, поскольку это распределение вероятностей для случайной величины C, мы знаем, что они должны суммироваться в 1. Следовательно, нам нужно нормализовать значения, вычислив α такое, что α*0.08 + α*0.02 = 1. α = 1 / (0.08+0.02) = 10. Наконец, мы можем сказать, что P(C | дождь) = <0.8, 0.2>.

**Правила вероятности**

1.  **Отрицание:** P(¬a) = 1 - P(a). Это следует из того, что сумма вероятностей всех возможных миров равна 1, а дополнительные литералы a и ¬a включают все возможные миры.
2.  **Включение-исключение:** P(a ∨ b) = P(a) + P(b) - P(a ∧ b). Это можно интерпретировать следующим образом: миры, в которых истинно a или b, равны всем мирам, где истинно a, плюс мирам, где истинно b. Однако в этом случае некоторые миры учитываются дважды (миры, где истинны и a, и b). Чтобы устранить это перекрытие, мы вычитаем один раз миры, где истинны и a, и b (поскольку они были посчитаны дважды).
    *   *Пример извне лекции:* предположим, я ем мороженое в 80% дней и печенье в 70% дней. Если мы вычисляем вероятность того, что сегодня я съем мороженое или печенье P(мороженое ∨ печенье), не вычитая P(мороженое ∧ печенье), мы ошибочно получаем 0.7 + 0.8 = 1.5. Это противоречит аксиоме о том, что вероятность находится в диапазоне от 0 до 1. Чтобы исправить двойной счет дней, когда я ел и мороженое, и печенье, нам нужно вычесть P(мороженое ∧ печенье) один раз.
3.  **Маргинализация (суммирование):** P(a) = P(a, b) + P(a, ¬b). Идея здесь в том, что b и ¬b являются непересекающимися событиями. То есть, вероятность одновременного occurrence b и ¬b равна 0. Мы также знаем, что b и ¬b в сумме дают 1. Таким образом, когда происходит a, b может либо произойти, либо нет. Когда мы берем вероятность того, что произошли и a, и b, плюс вероятность того, что произошли a и ¬b, мы в конечном итоге получаем просто вероятность a.
    *   Маргинализация может быть выражена для случайных величин следующим образом:
![image](./.assets/image-1760818816794.png)

        `P(X = xᵢ) = Σⱼ P(X = xᵢ, Y = yⱼ)`
    *   Левая часть уравнения означает «Вероятность того, что случайная величина X примет значение xᵢ». Например, для переменной C, которую мы упоминали ранее, два возможных значения — это облака утром и отсутствие облаков утром. Правая часть уравнения — это идея маргинализации. P(X = xᵢ) равна сумме совместных вероятностей xᵢ и каждого отдельного значения случайной величины Y. Например, P(C = облака) = P(C = облака, R = дождь) + P(C = облака, R = ¬дождь) = 0.08 + 0.32 = 0.4.
4.  **Усреднение ( conditioning ): ** P(a) = P(a | b)P(b) + P(a | ¬b)P(¬b). Это идея, похожая на маргинализацию. Вероятность наступления события a равна вероятности a при условии b, умноженной на вероятность b, плюс вероятность a при условии ¬b, умноженной на вероятность ¬b.
    *   В формулировке для случайных величин:
      
![image](./.assets/image-1760818831034.png)

        `P(X = xᵢ) = Σⱼ P(X = xᵢ | Y = yⱼ) P(Y = yⱼ)`
    *   В этой формуле случайная величина X принимает значение xᵢ с вероятностью, равной сумме вероятностей xᵢ при каждом значении случайной величины Y, умноженных на вероятность того, что переменная Y примет это значение. Это имеет смысл, если вспомнить, что P(a | b) = P(a, b) / P(b). Если мы умножим это выражение на P(b), мы получим P(a, b), и отсюда мы поступим так же, как и при маргинализации.

**Байесовские сети**

Байесовская сеть — это структура данных, которая представляет зависимости между случайными величинами. Байесовские сети обладают следующими свойствами:

*   Это направленные ациклические графы.
*   Каждый узел в графе представляет случайную величину.
*   Стрелка от X к Y означает, что X является родителем Y. То есть распределение вероятностей Y зависит от значения X.
*   Каждый узел X имеет распределение вероятностей P(X | Родители(X)).

Рассмотрим пример байесовской сети, которая включает переменные, влияющие на то, попадем ли мы на встречу вовремя.

![image](./.assets/image-1760818854908.png)

**Байесовская сеть**
[Граф: Дождь -> (Техобслуживание, Поезд) ; Техобслуживание -> Поезд; Поезд -> Встреча]

Опишем эту байесовскую сеть сверху вниз:

*   **Дождь** — это корневой узел в этой сети. Это означает, что его распределение вероятностей не зависит от предыдущих событий. В нашем примере Дождь — это случайная величина, которая может принимать значения {нет, слабый, сильный} со следующим распределением вероятностей:
    *   нет: 0.7
    *   слабый: 0.2
    *   сильный: 0.1
*   **Техобслуживание** в нашем примере кодирует, есть ли техническое обслуживание путей, принимая значения {да, нет}. Дождь является родительским узлом для Техобслуживания, что означает, что на распределение вероятностей Техобслуживания влияет Дождь. Это представлено таблицей условных вероятностей P(Техобслуживание | Дождь):

    | Дождь | yes | no |
    | :--- | :--- | :--- |
    | none | 0.4 | 0.6 |
    | light | 0.2 | 0.8 |
    | heavy | 0.1 | 0.9 |

*   **Поезд** — это переменная, которая кодирует, приходит ли поезд вовремя или задерживается, принимая значения {по расписанию, задержан}. Обратите внимание, что на Поезд указывают стрелки от both Техобслуживания и Дождя. Это означает, что оба являются родителями Поезда, и их значения влияют на распределение вероятностей Поезда. Это представлено таблицей P(Поезд | Дождь, Техобслуживание):

    | Дождь | Техобсл. | on time | delayed |
    | :--- | :--- | :--- | :--- |
    | none | yes | 0.8 | 0.2 |
    | none | no | 0.9 | 0.1 |
    | light | yes | 0.6 | 0.4 |
    | light | no | 0.7 | 0.3 |
    | heavy | yes | 0.4 | 0.6 |
    | heavy | no | 0.5 | 0.5 |

*   **Встреча** — это случайная величина, которая представляет, посетим ли мы встречу, принимая значения {посетим, пропустим}. Обратите внимание, что его единственный родитель — Поезд. Этот момент в байесовских сетях важен: родители включают только прямые связи. Верно, что техобслуживание влияет на то, придет ли поезд вовремя, а то, придет ли поезд вовремя, влияет на то, попадем ли мы на встречу. Однако в конечном счете на наши шансы попасть на встречу напрямую влияет то, пришел ли поезд вовремя, и это отражено в байесовской сети. Это представлено таблицей P(Встреча | Поезд):

    | Поезд | attend | miss |
    | :--- | :--- | :--- |
    | on time | 0.9 | 0.1 |
    | delayed | 0.6 | 0.4 |

Например, если мы хотим найти вероятность пропуска встречи, когда поезд задержан в день без техобслуживания и со слабым дождем, то есть P(слабый, нет, задержан, пропуск), мы вычислим следующее: P(слабый) * P(нет | слабый) * P(задержан | слабый, нет) * P(пропуск | задержан). Значение каждой отдельной вероятности можно найти в распределениях вероятностей выше, а затем эти значения перемножаются, чтобы получить P(нет, слабый, задержан, пропуск).

**Вывод (Inference)**

На прошлой лекции мы рассматривали вывод через логическое следование (entailment). Это означало, что мы могли однозначно делать выводы на основе уже имеющейся информации. Мы также можем выводить новую информацию на основе вероятностей. Хотя это не позволяет нам узнать новую информацию наверняка, это позволяет выяснить распределения вероятностей для некоторых значений. Вывод имеет несколько составляющих.

*   **Запрос X:** переменная, для которой мы хотим вычислить распределение вероятностей.
*   **Переменные свидетельства E:** одна или несколько переменных, которые были наблюдены для события e. Например, мы можем наблюдать, что дождь слабый, и это наблюдение помогает нам вычислить вероятность задержки поезда.
*   **Скрытые переменные Y:** переменные, которые не являются запросом и также не были наблюдены. Например, стоя на вокзале, мы можем наблюдать, есть ли дождь, но мы не можем знать, есть ли техническое обслуживание путей дальше по маршруту. Таким образом, Техобслуживание будет скрытой переменной в этой ситуации.
*   **Цель:** вычислить P(X | e). Например, вычислить распределение вероятностей переменной Поезд (запрос) на основе свидетельства e, что мы знаем о слабом дожде.

Приведем пример. Мы хотим вычислить распределение вероятностей переменной Встреча при условии, что дождь слабый и техобслуживания нет. То есть мы знаем, что дождь слабый и техобслуживания нет, и мы хотим выяснить, какова вероятность того, что мы посетим встречу и пропустим встречу, P(Встреча | слабый, нет). Из раздела о совместной вероятности мы знаем, что мы можем выразить возможные значения случайной величины Встреча как пропорцию, переписав P(Встреча | слабый, нет) как α * P(Встреча, слабый, нет). Как мы можем вычислить распределение вероятностей Встреча, если ее родителем является только переменная Поезд, а не Дождь или Техобслуживание? Здесь мы используем маргинализацию. Значение P(Встреча, слабый, нет) равно α * [P(Встреча, слабый, нет, задержан) + P(Встреча, слабый, нет, по расписанию)].

**Вывод перечислением (Inference by Enumeration)**

Вывод перечислением — это процесс нахождения распределения вероятностей переменной X при заданных наблюдениях e и некоторых скрытых переменных Y.

**Формула вывода перечислением**

![image](./.assets/image-1760818875504.png)

`P(X | e) = α Σy P(X, e, y)`

В этом уравнении X обозначает переменную запроса, e — наблюдаемые свидетельства, y — все значения скрытых переменных, а α нормализует результат так, чтобы мы получили вероятности, сумма которых равна 1. Если объяснить уравнение словами, оно гласит, что распределение вероятностей X при условии e равно нормированному распределению вероятностей X и e. Чтобы получить это распределение, мы суммируем нормированную вероятность X, e и y, где y каждый раз принимает different значение скрытых переменных Y.

( *Далее следует пример кода на Python с использованием библиотеки pomegranate для создания байесовской сети и выполнения вероятностного вывода. Код остается на английском, так как это стандартная практика для программирования.* )

...

**Сэмплирование (Sampling)**

Сэмплирование — это один из методов приближенного вывода. При сэмплировании каждое переменное значение выбирается (сэмплируется) в соответствии с его распределением вероятностей. Мы начнем с примера извне лекции, а затем рассмотрим пример из лекции.

Чтобы сгенерировать распределение с помощью сэмплирования с помощью игральной кости, мы можем бросить кость много раз и записать, какое значение мы получали каждый раз. Предположим, мы бросили кость 600 раз. Мы подсчитываем, сколько раз мы получили 1 (должно быть roughly 100), и затем повторяем для остальных значений 2-6. Затем мы делим каждое count на общее количество бросков. Это сгенерирует приблизительное распределение значений броска кости: с одной стороны, маловероятно, что мы получим результат, когда каждое значение имеет вероятность 1/6 (точная вероятность), но мы получим значение, близкое к нему.

Вот пример из лекции: если мы начнем с сэмплирования переменной Дождь, значение 'нет' будет сгенерировано с вероятностью 0.7, значение 'слабый' — с вероятностью 0.2, а значение 'сильный' — с вероятностью 0.1. Предположим, что полученное сэмплированное значение — 'нет'. Когда мы доберемся до переменной Техобслуживание, мы также сэмплируем ее, но только из распределения вероятностей, где Дождь равен 'нет', потому что это уже сэмплированный результат. Мы продолжим делать это для всех узлов. Теперь у нас есть один образец (sample), и повторение этого процесса много раз генерирует распределение. Теперь, если мы хотим ответить на вопрос, например, чему равно P(Поезд = по расписанию), мы можем подсчитать количество samples, где переменная Поезд имеет значение 'по расписанию', и разделить результат на общее количество samples. Таким образом, мы только что сгенерировали приблизительную вероятность для P(Поезд = по расписанию).

Мы также можем отвечать на вопросы, которые включают условную вероятность, например, P(Дождь = слабый | Поезд = по расписанию). В этом случае мы игнорируем все samples, где значение Поезд не 'по расписанию', а затем действуем как прежде. Мы подсчитываем, сколько samples имеют переменную Дождь = слабый среди тех samples, где Поезд = по расписанию, а затем делим на общее количество samples, где Поезд = по расписанию.

```python
import pomegranate

from collections import Counter

from model import model

def generate_sample():

    # Mapping of random variable name to sample generated
    sample = {}

    # Mapping of distribution to sample generated
    parents = {}

    # Loop over all states, assuming topological order
    for state in model.states:

        # If we have a non-root node, sample conditional on parents
        if isinstance(state.distribution, pomegranate.ConditionalProbabilityTable):
            sample[state.name] = state.distribution.sample(parent_values=parents)

        # Otherwise, just sample from the distribution alone
        else:
            sample[state.name] = state.distribution.sample()

        # Keep track of the sampled value in the parents mapping
        parents[state.distribution] = sample[state.name]

    # Return generated sample
    return sample
```

Теперь для вычисления P(*Назначение | Train = delayed*), которое является распределением вероятности переменной Appointment при условии, что поезд задерживается, мы делаем следующее:

```python
# Rejection sampling
# Compute distribution of Appointment given that train is delayed
N = 10000
data = []

# Repeat sampling 10,000 times
for i in range(N):

    # Generate a sample based on the function that we defined earlier
    sample = generate_sample()

    # If, in this sample, the variable of Train has the value delayed, save the sample. Since we are interested interested in the probability distribution of Appointment given that the train is delayed, we discard the sampled where the train was on time.
    if sample["train"] == "delayed":
        data.append(sample["appointment"])

# Count how many times each value of the variable appeared. We can later normalize by dividing the results by the total number of saved samples to get the approximate probabilities of the variable that add up to 1.
print(Counter(data))
```
---
**Взвешивание по правдоподобию (Likelihood Weighting)**

В примере с сэмплированием выше мы отбрасывали samples, которые не соответствовали имеющимся у нас свидетельствам. Это неэффективно. Один из способов обойти это — использовать взвешивание по правдоподобию, выполнив следующие steps:

1.  Начните с фиксации значений для переменных свидетельства.
2.  Сэмплируйте переменные, не являющиеся свидетельствами, используя условные вероятности в байесовской сети.
3.  Взвесьте каждый sample по его правдоподобию: вероятности occurrence всех свидетельств.

Например, если у нас есть наблюдение, что поезд был по расписанию, мы начнем сэмплирование как раньше. Мы сэмплируем значение Дождя по его распределению, затем Техобслуживания, но когда мы доберемся до Поезда — мы всегда присваиваем ему наблюдаемое значение, в нашем случае 'по расписанию'. Затем мы продолжаем и сэмплируем Встречу на основе ее распределения вероятностей при условии Поезд = по расписанию. Теперь, когда этот sample существует, мы взвешиваем его по условной вероятности наблюдаемой переменной при condition ее сэмплированных родителей. То есть, если мы сэмплировали Дождь и получили 'слабый', а затем сэмплировали Техобслуживание и получили 'да', то мы взвесим этот sample на P(Поезд = по расписанию | слабый, да).

**Марковские модели (Markov Models)**

До сих пор мы рассматривали вопросы вероятности при наличии некоторой наблюдаемой информации. В этой парадигме измерение времени никак не представлено. Однако многие задачи rely на измерении времени, такие как прогнозирование. Чтобы представить переменную времени, мы создадим новую переменную, X, и будем изменять ее в зависимости от интересующего события, так что Xₜ — это текущее событие, Xₜ₊₁ — следующее событие и так далее. Чтобы иметь возможность предсказывать события в будущем, мы будем использовать марковские модели.

**Марковское предположение**

Марковское предположение — это предположение, что текущее состояние зависит только от конечного фиксированного числа предыдущих состояний. Это важно для нас. Подумайте о задаче прогнозирования погоды. Теоретически, мы могли бы использовать все данные за прошлый год, чтобы предсказать завтрашнюю погоду. Однако это нецелесообразно как из-за вычислительной мощности, которая для этого потребуется, так и потому, что, вероятно, нет информации об условной вероятности завтрашней погоды based on погоде 365 дней назад. Используя марковское предположение, мы ограничиваем наши предыдущие состояния (например, сколько предыдущих дней мы будем учитывать при прогнозировании завтрашней погоды), делая задачу управляемой. Это означает, что мы можем получить более грубое приближение интересующих вероятностей, но часто этого достаточно для наших нужд. Более того, мы можем использовать марковскую модель, основанную на информации о последнем событии (например, прогнозирование завтрашней погоды на основе сегодняшней).

**Марковская цепь**

Марковская цепь — это последовательность случайных величин, где распределение каждой переменной подчиняется марковскому предположению. То есть каждое событие в цепи происходит based on вероятности события перед ним.

Чтобы начать построение марковской цепи, нам нужна модель переходов, которая будет определять распределения вероятностей следующего события на основе возможных значений текущего события.

**Модель переходов**

![image](./.assets/image-1760818998218.png)
| Сегодня \ Завтра | sun | rain |
| :--- | :--- | :--- |
| sun | 0.8 | 0.2 |
| rain | 0.3 | 0.7 |

В этом примере вероятность того, что завтра будет солнечно, при условии, что сегодня солнечно, равна 0.8. Это разумно, потому что более вероятно, что солнечный день последует за солнечным днем. Однако, если сегодня дождливо, вероятность дождя завтра равна 0.7, поскольку дождливые дни с большей вероятностью следуют друг за другом. Используя эту модель переходов, можно сэмплировать марковскую цепь. Начните с того, что день будет либо дождливым, либо солнечным, а затем сэмплируйте следующий день based on вероятности того, что он будет солнечным или дождливым, учитывая погоду сегодня. Затем обусловьте вероятность послезавтрашнего дня based on завтрашнему дню и так далее, получив марковскую цепь.

![image](./.assets/image-1760819017116.png)

```python
from pomegranate import *

# Define starting probabilities
start = DiscreteDistribution({
    "sun": 0.5,
    "rain": 0.5
})

# Define transition model
transitions = ConditionalProbabilityTable([
    ["sun", "sun", 0.8],
    ["sun", "rain", 0.2],
    ["rain", "sun", 0.3],
    ["rain", "rain", 0.7]
], [start])

# Create Markov chain
model = MarkovChain([start, transitions])

# Sample 50 states from chain
print(model.sample(50))
```
---

**Скрытые марковские модели (Hidden Markov Models)**

Скрытая марковская модель — это тип марковской модели для системы со скрытыми состояниями, которые порождают некоторое наблюдаемое событие. Это означает, что иногда ИИ имеет некоторые измерения мира, но не имеет доступа к точному состоянию мира. В этих случаях состояние мира называется скрытым состоянием, а любые данные, к которым имеет доступ ИИ, являются наблюдениями. Вот несколько примеров:

*   Для робота, исследующего неизведанную территорию, скрытым состоянием является его положение, а наблюдением — данные, записанные датчиками робота.
*   В распознавании речи скрытым состоянием являются произнесенные слова, а наблюдением — аудио-волны.
*   При измерении вовлеченности пользователей на веб-сайтах скрытым состоянием является то, насколько пользователь вовлечен, а наблюдением — аналитика веб-сайта или приложения.

Для нашего обсуждения мы будем использовать следующий пример. Наш ИИ хочет определить погоду (скрытое состояние), но у него есть доступ только к внутренней камере, которая записывает, сколько людей принесло с собой зонтики. Вот наша модель датчика (также называемая моделью эмиссии), которая представляет эти вероятности:

**Модель датчика**

![image](./.assets/image-1760819055233.png)

| Погода \ Наблюдение | umbrella | no umbrella |
| :--- | :--- | :--- |
| sun | 0.2 | 0.8 |
| rain | 0.9 | 0.1 |

В этой модели, если солнечно, наиболее вероятно, что люди не принесут зонтики в здание. Если дождливо, то очень вероятно, что люди принесут зонтики в здание. Используя наблюдение за тем, принесли ли люди зонтик или нет, мы можем предсказать с разумной вероятностью, какая погода на улице.

**Предположение марковости датчика**

Предположение, что переменная свидетельства зависит только от соответствующего состояния. Например, для наших моделей мы предполагаем, что то, приносят ли люди зонтики в офис, зависит только от погоды. Это не обязательно отражает полную истину, потому что, например, более сознательные, не любящие дождь люди могут брать зонтик с собой везде, даже когда солнечно, и если бы мы знали личности всех, это добавило бы больше данных в модель. Однако предположение марковости датчика игнорирует эти данные, предполагая, что только скрытое состояние влияет на наблюдение.

Скрытую марковскую модель можно представить в марковской цепи с двумя слоями. Верхний слой, переменная X, обозначает скрытое состояние. Нижний слой, переменная E, обозначает свидетельство, наблюдения, которые у нас есть.


![image](./.assets/image-1760819070490.png)


На основе скрытых марковских моделей можно выполнять several задачи:

*   **Фильтрация (Filtering):** по наблюдениям от начала до текущего момента вычислить распределение вероятностей для текущего состояния. Например, имея информацию о том, когда люди приносили зонтики с начала времен до сегодняшнего дня, мы генерируем распределение вероятностей для того, идет ли дождь сегодня или нет.
*   **Прогнозирование (Prediction):** по наблюдениям от начала до текущего момента вычислить распределение вероятностей для будущего состояния.
*   **Сглаживание (Smoothing):** по наблюдениям от начала до текущего момента вычислить распределение вероятностей для прошлого состояния. Например, вычисление вероятности дождя вчера при условии, что сегодня люди принесли зонтики.
*   **Наиболее вероятное объяснение (Most likely explanation):** по наблюдениям от начала до текущего момента вычислить наиболее вероятную последовательность событий.

Задача наиболее вероятного объяснения может использоваться в таких процессах, как распознавание речи, когда на основе нескольких аудио-волн ИИ определяет наиболее вероятную последовательность слов или слогов, которая привела к этим волнам. Далее следует реализация скрытой марковской модели на Python для задачи наиболее вероятного объяснения:

```python
from pomegranate import *

# Observation model for each state
sun = DiscreteDistribution({
    "umbrella": 0.2,
    "no umbrella": 0.8
})

rain = DiscreteDistribution({
    "umbrella": 0.9,
    "no umbrella": 0.1
})

states = [sun, rain]

# Transition model
transitions = numpy.array(
    [[0.8, 0.2], # Tomorrow's predictions if today = sun
     [0.3, 0.7]] # Tomorrow's predictions if today = rain
)

# Starting probabilities
starts = numpy.array([0.5, 0.5])

# Create the model
model = HiddenMarkovModel.from_matrix(
    transitions, states, starts,
    state_names=["sun", "rain"]
)
model.bake()
```

Обратите внимание, что в нашей модели есть как сенсорная модель, так и модель перехода. Для скрытой марковской модели нам нужны и то, и другое. В следующем фрагменте кода мы видим последовательность наблюдений за тем, принесли ли люди зонтики в здание или нет, и на основе этой последовательности мы запустим модель, которая сгенерирует и распечатает наиболее вероятное объяснение (т.е. последовательность погоды, которая, скорее всего, привела к этому шаблону наблюдений):

```python
from model import model

# Observed data
observations = [
    "umbrella",
    "umbrella",
    "no umbrella",
    "umbrella",
    "umbrella",
    "umbrella",
    "umbrella",
    "no umbrella",
    "no umbrella"
]

# Predict underlying states
predictions = model.predict(observations)
for prediction in predictions:
    print(model.states[prediction].name)
```

В этом случае на выходе программы будет дождь, дождь, солнце, дождь, дождь, дождь, дождь, солнце, солнце. Эти выходные данные представляют собой наиболее вероятную модель погоды, учитывая наши наблюдения за людьми, приносящими или не приносящими зонтики в здание.


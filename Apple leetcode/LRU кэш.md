# LRU кэш

Спроектируйте структуру данных, которая соответствует ограничениям кэша с использованием алгоритма Least Recently Used (LRU)
Реализуйте класс `LRUCache`:

* `LRUCache(int capacity)` инициализирует экземпляр LRU кэша с полем `capacity`, имеющим **положительное** значение.
* `int get(int key)` возвращает значение по ключу `key`, если ключ существует, иначе возвращает `-1`.
* `void put(int key, int value)` обновляет значение по ключу `key`, если ключ существует. Иначе, добавляет пару ключ-значение в кэш. Если количество ключей превышает `capacity`, то **удаляет** ключ, который запрашивался реже всего.

Методы `get` и `put` должны выполняться в среднем за `O(1)`.

**Пример 1:**

**Ввод:** 
["LRUCache", "put", "put", "get", "put", "get", "put", "get", "get", "get"]
[[2], [1, 1], [2, 2], [1], [3, 3], [2], [4, 4], [1], [3], [4]]
**Вывод:** 
[null, null, null, 1, null, -1, null, -1, 3, 4]

**Пояснение:** 
LRUCache lRUCache = new LRUCache(2);
lRUCache.put(1, 1); // кэш: {1=1}
lRUCache.put(2, 2); // кэш: {1=1, 2=2}
lRUCache.get(1);    // возвращаем 1
lRUCache.put(3, 3); // наименее запрашиваемый ключ это 2, удаляем ключ 2, кэш: {1=1, 3=3}
lRUCache.get(2);    // возвращаем -1 (не найден)
lRUCache.put(4, 4); // наименее запрашиваемый ключ это 1, удаляем ключ 1, кэш: {4=4, 3=3}
lRUCache.get(1);    // возвращаем -1 (не найден)
lRUCache.get(3);    // возвращаем 3
lRUCache.get(4);    // возвращаем 4

# Решение

```c++
class LRUCache {
public:
    class Node {
    public:
        int key;
        int val;
        Node* prev;
        Node* next;

        Node(int key, int val) {
            this->key = key;
            this->val = val;
        }
    };

    Node* head = new Node(-1, 1);
    Node* tail = new Node(-1, 1);

    int cap;
    unordered_map<int, Node*> m;

    LRUCache(int capacity) {
        cap = capacity;
        head->next = tail;
        tail->next = head;
    }
    void addNode(Node* newnode) {
        Node* temp = head->next;

        newnode->next = temp;
        newnode->prev = head;

        head->next = newnode;
        temp->prev = newnode;
    }
    void deleteNode(Node* delnode) {
        Node* prevv = delnode->prev;
        Node* nextt = delnode->next;

        prevv->next = nextt;
        nextt->prev = prevv;
    }

    int get(int key) {
        if (m.find(key) != m.end()) {
            Node* resNode = m[key];
            int ans = resNode->val;
            m.erase(key);
            deleteNode(resNode);
            addNode(resNode);

            m[key] = head->next;
            return ans;
        }
        return -1;

    }

    void put(int key, int value) {
        if (m.find(key) != m.end()) {
            Node* curr = m[key];
            m.erase(key);
            deleteNode(curr);
        }
        if (m.size() == cap) {
            m.erase(tail->prev->key);
            deleteNode(tail->prev);
        }
        addNode(new Node(key, value));
        m[key] = head->next;
    }
};
auto init = atexit([]() { ofstream("display_runtime.txt") << "0";});
```

# Разбор

## Введение: Что такое LRU Cache? (Аналогия с полкой для книг)

Представь, что у тебя есть маленькая полка, на которую помещается всего 5 книг. Ты постоянно читаешь разные книги. Чтобы полка не захламлялась, ты договариваешься сам с собой о простом правиле:

* Когда ты берёшь книгу с полки почитать, ты, закончив, ставишь её на **самый левый край**.
* Когда ты покупаешь **новую** книгу, ты тоже ставишь её на **самый левый край**.
* Если для новой книги **нет места**, ты убираешь с полки самую **правую** книгу (ту, которую ты не трогал дольше всего).

**LRU Cache (Least Recently Used Cache)** — это в точности такая "полка" в программировании. "Левый край" — это самые свежие, недавно использованные данные. "Правый край" — самые старые, кандидаты на удаление.

Наша задача — реализовать эту логику максимально быстро. Нам нужно:

1. **Мгновенно находить книгу (данные) по названию (ключу).**
2. **Очень быстро перемещать книгу на левый край.**
3. **Очень быстро убирать книгу с правого края.**

Для этого код использует две структуры данных: **хэш-таблицу** (для мгновенного поиска) и **двусвязный список** (для быстрых перемещений).

---

## Часть 1: "Кирпичик" нашего хранилища — `class Node`

Это основа нашего списка, "книга с закладками" на соседей.

### Код

```cpp
class LRUCache {
public:
    class Node {
    public:
        int key;   // "Название" книги (уникальный идентификатор)
        int val;   // "Содержание" книги (данные, которые мы храним)
        Node* prev; // "Закладка", указывающая на предыдущую книгу на полке
        Node* next; // "Закладка", указывающая на следующую книгу на полке

        // Конструктор: "Печатаем" новую книгу с названием и содержанием
        Node(int key, int val) {
            this->key = key;
            this->val = val;
        }
    };
// ... остальной код
```

### Пояснение

Класс `Node` — это шаблон для объекта, который будет хранить наши данные. Каждый такой объект (узел) — это элемент в нашей цепочке.

* `int key;`: Ключ. Это уникальный номер, по которому мы будем искать наши данные. Например, ID пользователя. Нам нужно хранить его прямо в узле, чтобы, когда мы решим удалить самый старый узел, мы знали, какой ключ стереть из нашей "таблицы быстрого доступа".
* `int val;`: Значение. Это и есть полезная информация, которую мы хотим сохранить. Например, имя пользователя.
* `Node* prev;` и `Node* next;`: Указатели. Это самое важное. Они, как сцепки у вагонов поезда, связывают узлы в единую цепь. `next` указывает на следующий узел в списке, а `prev` — на предыдущий. Благодаря тому, что узел знает и соседа справа, и соседа слева, список называется **двусвязным**. Это даёт нам суперспособность: если мы находимся у любого вагона, мы можем мгновенно отцепить его, соединив два соседних вагона напрямую.

---

## Часть 2: "Мозг" и "Скелет" кэша — Поля класса `LRUCache`

Здесь мы создаём саму "полку" и "каталог" для неё.

### Код

```cpp
// ... внутри class LRUCache
    Node* head = new Node(-1, -1);
    Node* tail = new Node(-1, -1);

    int cap;
    unordered_map<int, Node*> m;
// ... остальной код
```

### Пояснение

* `int cap;`: Сокращение от `capacity` (ёмкость). Это просто число, которое хранит максимальный размер нашей "полки".
* `unordered_map<int, Node*> m;`: **Это наш "каталог" или "указатель"**.
    * `unordered_map` (хэш-таблица) — это структура, которая позволяет хранить пары "ключ-значение" и находить значение по ключу практически мгновенно (в среднем за O(1)).
    * `int`: Тип ключа. Это то же самое, что и `key` в нашем `Node`.
    * `Node*`: Тип значения. А вот это самое интересное! Мы храним не сами данные, а **указатель** — точный "адрес в памяти" на нужный нам узел (`Node`) в нашем списке.
    * **Связка:** Когда нас просят найти данные по ключу `5`, мы заглядываем в `m`, мгновенно находим запись для ключа `5` и получаем адрес вагона, в котором лежат эти данные.
* `Node* head = new Node(-1, -1);` и `Node* tail = new Node(-1, -1);`: **Сторожевые узлы**. Это очень умный трюк.
    * `head` (голова) и `tail` (хвост) — это **фиктивные** узлы. Они не хранят реальных данных. Они как локомотив и последний вагон-платформа в поезде — всегда на своих местах.
    * **Зачем они?** Чтобы наш код был проще. Настоящий первый ("самый свежий") элемент всегда будет `head->next`. Настоящий последний ("самый старый") — `tail->prev`. Благодаря этому нам не нужно писать проверки вроде "а что, если мы удаляем самый первый элемент?" или "а что, если список пуст?". Любой реальный узел всегда будет находиться *между* другими узлами (даже если это `head` и `tail`).

---

## Часть 3: Подготовка к работе — Конструктор `LRUCache`

Здесь мы собираем нашу пустую "полку".

### Код

```cpp
// ... внутри class LRUCache
    LRUCache(int capacity) {
        cap = capacity;      // Запоминаем максимальный размер
        head->next = tail;   // Голова изначально указывает на хвост
        tail->prev = head;   // Хвост изначально указывает назад на голову
    }
// ... остальной код
```

### Пояснение

Когда мы создаём объект `LRUCache`, конструктор выполняет первоначальную настройку:

1. Сохраняет переданный `capacity` в поле `cap`.
2. Связывает `head` и `tail` друг с другом. `head->next = tail` означает, что после головы сразу идёт хвост. `tail->prev = head` означает, что перед хвостом сразу идёт голова. Это состояние нашего двусвязного списка, когда он пуст. Он готов к добавлению "вагонов" между локомотивом и последней платформой.

---

## Часть 4: Базовые манипуляции — `addNode` и `deleteNode`

Это низкоуровневые "инструменты" для работы с нашим списком.

### Код `addNode`

```cpp
// ... внутри class LRUCache
    // Эта функция всегда добавляет узел в самое начало списка (сразу после head)
    void addNode(Node* newnode) {
        Node* temp = head->next; // 1. Запоминаем, какой узел был первым (старый первый)

        newnode->next = temp;    // 2. Новый узел должен указывать на старый первый
        newnode->prev = head;    // 3. Новый узел должен указывать назад на голову

        head->next = newnode;    // 4. Голова теперь должна указывать на наш новый узел
        temp->prev = newnode;    // 5. Старый первый узел должен указывать назад на новый
    }
```

### Пояснение `addNode`

Эта функция вставляет узел на позицию "самого свежего". Представь, что у нас есть `[HEAD]` и `[FIRST_NODE]`. Мы хотим вставить `[NEW_NODE]` между ними.

1. `head->next` указывает на `[FIRST_NODE]`. Мы сохраняем этот указатель.
2. Мы "программируем" сцепки нового узла: его `next` будет `[FIRST_NODE]`, а `prev` — `[HEAD]`.
3. Теперь мы перенаправляем сцепки соседей: `next` у `[HEAD]` теперь указывает на `[NEW_NODE]`, а `prev` у `[FIRST_NODE]` тоже указывает на `[NEW_NODE]`.

Цепочка собрана! `[HEAD] <-> [NEW_NODE] <-> [FIRST_NODE]`. Всё это — лишь переназначение четырёх "адресов", что очень быстро.

### Код `deleteNode`

```cpp
// ... внутри class LRUCache
    // Эта функция "вырезает" узел из списка, соединяя его соседей
    void deleteNode(Node* delnode) {
        Node* prevv = delnode->prev; // 1. Находим соседа слева
        Node* nextt = delnode->next; // 2. Находим соседа справа

        prevv->next = nextt; // 3. "Протягиваем" связь от левого соседа к правому
        nextt->prev = prevv; // 4. "Протягиваем" обратную связь от правого к левому
    }
```

### Пояснение `deleteNode`

Это ключевой момент эффективности. Эта функция **не удаляет объект из памяти**. Она лишь исключает его из списка.
Представь цепочку `[A] <-> [B] <-> [C]`. Мы хотим "вырезать" `[B]`.

1. Мы берём соседа `[B]` слева (`[A]`) и соседа справа (`[C]`).
2. Мы говорим `[A]`: "Твой следующий узел теперь не `[B]`, а `[C]`".
3. Мы говорим `[C]`: "Твой предыдущий узел теперь не `[B]`, а `[A]`".

В итоге получается цепочка `[A] <-> [C]`. Узел `[B]` остался в памяти, но он больше не в списке. Мы можем его либо окончательно удалить, либо, что ещё лучше, **переиспользовать**, вставив в другое место.

---

## Часть 5: Чтение из кэша — `get(int key)`

Это операция "взять книгу с полки и поставить её на левый край".

### Код

```cpp
// ... внутри class LRUCache
    int get(int key) {
        // 1. Ищем ключ в нашем "каталоге"
        if (m.find(key) != m.end()) {
            // Если нашли...
            Node* resNode = m[key];  // 2. Получаем прямой адрес узла из каталога
            int ans = resNode->val;  // 3. Запоминаем значение, чтобы вернуть его в конце

            // 4. Обновляем позицию узла: он теперь самый свежий
            m.erase(key);         // Временно удаляем из каталога (для чистоты)
            deleteNode(resNode);  // Вырезаем узел из его текущего места в списке
            addNode(resNode);     // И вставляем ЭТОТ ЖЕ узел в самое начало

            m[key] = head->next;  // 5. Обновляем каталог: теперь ключ указывает на узел на новом месте
            return ans;           // 6. Возвращаем значение
        }
        return -1; // Если в каталоге ключа нет, возвращаем -1
    }
```

### Пояснение

1. Сначала мы лезем в `unordered_map` `m`. Это очень быстро.
2. Если ключ найден (`m.find(key) != m.end()`), это значит, "книга на полке есть".
3. Мы получаем из `m` прямой указатель на `Node`.
4. Сохраняем его значение (`val`), ведь именно его нас просили найти.
5. **Вот магия LRU:** Мы должны переместить этот узел в начало. Мы используем наши инструменты:
    * `deleteNode(resNode)`: "Вырезаем" узел из его текущей позиции (может, он был в середине или в конце).
    * `addNode(resNode)`: "Вставляем" этот же, уже существующий, узел в самое начало списка. **Мы не создаём новый объект!** Мы просто двигаем старый. Это суперэффективно.
6. Обновляем наш каталог `m`, чтобы он теперь указывал на этот узел на его новом, "свежем" месте.
7. Возвращаем значение.

---

## Часть 6: Запись в кэш — `put(int key, int value)`

Это операция "поставить новую (или обновлённую) книгу на левый край, при необходимости выкинув самую старую".

### Код

```cpp
// ... внутри class LRUCache
    void put(int key, int value) {
        // 1. Проверяем, может, такая книга уже есть на полке?
        if (m.find(key) != m.end()) {
            Node* curr = m[key]; // Находим существующий узел
            m.erase(key);        // Удаляем старую запись из каталога
            deleteNode(curr);    // Вырезаем узел из списка
            // Примечание: тут мы его удаляем, а потом создаём новый.
            // Можно было бы оптимизировать и просто поменять curr->val и переместить.
        }
        // 2. Проверяем, не заполнена ли полка до отказа
        if (m.size() == cap) {
            // Полка полная, нужно выкинуть самую старую книгу
            m.erase(tail->prev->key); // Находим ключ самого старого узла и удаляем из каталога
            deleteNode(tail->prev);   // Вырезаем самый старый узел (тот, что перед хвостом) из списка
        }

        // 3. "Печатаем" новую книгу и ставим её на левый край
        addNode(new Node(key, value));
        // 4. Добавляем запись о ней в наш каталог
        m[key] = head->next;
    }
```

### Пояснение

Здесь два главных сценария:

**Сценарий A: Мы обновляем существующую книгу (`if (m.find(key) != m.end())`)**

1. Мы находим старый узел, вырезаем его из списка и удаляем из каталога. По сути, мы полностью избавляемся от старой версии.
2. Далее код переходит к шагу 3, где для этой "обновлённой" книги создаётся совершенно новый узел и ставится в начало.

**Сценарий B: Мы добавляем новую книгу**

1. Сначала — проверка на вместимость. `if (m.size() == cap)`: если количество элементов в каталоге равно максимальной ёмкости...
2. ...мы должны освободить место. Самый старый элемент — это `tail->prev`.
    * `m.erase(tail->prev->key)`: Мы узнаём ключ этого старого узла и стираем его из каталога.
    * `deleteNode(tail->prev)`: Мы вырезаем сам узел из списка. Теперь он ни с чем не связан, и сборщик мусора (в C++ это нужно делать вручную, но здесь для простоты опустим) его уничтожит.
3. `addNode(new Node(key, value))`: Мы создаём **новый** узел с нужным ключом и значением и сразу ставим его в начало с помощью `addNode`.
4. `m[key] = head->next`: Регистрируем наш новый узел в каталоге `m`. `head->next` — это и есть только что добавленный узел.

Вот и всё! Комбинация быстрого каталога (`unordered_map`) и гибкого списка (`doubly linked list`) позволяет реализовать всю логику "полки для книг" невероятно эффективно.
